

# 第十章 模拟登陆

​	很多情况下，网站的一些数据需要登陆才能查看，例如GitHub的个人设置页码，如果不登录就无法查看；12306网站的提交订单页面，如果不登录就无法提交订单；想登陆微博写一个新内容，如果不登录也是无法发送的。

​	如果想要进行上述内容的操作，就需要实现模拟登陆的一些机制。

​	登陆一般需要两个内容---用户名和密码，也有的网站是填写手机号获取验证码，或者微信扫码，或者OAuth验证等，从根本上看，这些方式都是把一些可供认证的信息提交给服务器。

​	模拟登陆现在主要分为两种模式，一种是基于**Session和Cookie**的模拟登陆，一种是基于**JWT（JSON Web Token）**的模拟登陆。

## 10.1 基于Session和Cookie的模拟登陆

### 10.1.0 前言

1.无状态协议：Http

- 如上图所示，HTTP协议 是无状态的协议，用户浏览服务器上的内容，只需要发送页面请求，服务器返回内容。对于服务器来说，并不关心，也并不知道是哪个用户的请求。对于一般浏览性的网页来说，没有任何问题。
- 但是，现在很多的网站，是需要用户登录的。以淘宝为例：比如说某个用户想购买一个产品，当点击 “ 购买按钮 ” 时，由于HTTP协议 是无状态的，那对于淘宝来说，就不知道是哪个用户操作的。
- 为了实现这种用户标记，服务器就采用了cookie这种机制来识别具体是哪一个用户的访问。



2.了解cookie

- 为了实现用户标记，在Http无状态请求的基础之上，我们需要在请求中携带一些用户信息（比如用户名之类，这些信息是服务器发送到本地浏览器的，但是服务器并不存储这些信息），这就是cookie机制。

![img](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pbWctYmxvZy5jc2RuLm5ldC8yMDE4MDMxNjE1NTM0MTg1Mz93YXRlcm1hcmsvMi90ZXh0L0x5OWliRzluTG1OelpHNHVibVYwTDNwM2NUa3hNak14T0Rnek5BPT0vZm9udC81YTZMNUwyVC9mb250c2l6ZS80MDAvZmlsbC9JMEpCUWtGQ01BPT0vZGlzc29sdmUvNzA?x-oss-process=image/format,png)



### 10.1.1 Cookie原理

​		简单来说，打开网页登陆后，服务器会返回带有`Set-Cookie`字段的响应头，客户端会生成对应的`Cookie`,其中保存着与`SessionID`相关的信息，之后发送给服务器的请求都会携带这个生成的`Cookie`。服务器接收到请求后，会根据`Cookie`中保存的`SessionID`找到对应的`Session`，同时校验`Cookie`里的相关信息，如果当前`Session`是有效的，并且校验成功，服务器就判断当前用户已经登陆，返回所请求的页面信息。、

​	所以，这种模式的核心是获取客户端登陆生成的。

​	

![img](https://t11.baidu.com/it/u=2169381799,1320776160&fm=173&app=49&f=JPEG?w=450&h=300&s=440A5532435E4DC80AD4B1DB0000C0B2)

​	不同网站对于用户登陆状态的实现可能是不同的，但`Session`和`Cookie`一定是相互配合工作的。



​	会话Cookie示例：

<img src="C:\Users\ACG1314\AppData\Roaming\Typora\typora-user-images\image-20220510125028252.png" alt="image-20220510125028252" style="zoom: 80%;" />



​	持久cookies示例：

![image-20220510125120786](C:\Users\ACG1314\AppData\Roaming\Typora\typora-user-images\image-20220510125120786.png)



**cookie总结：**

- 是存储在客户端的一组键值对。
- web中cookie的典型应用：			
  - 免密登录
- cookie和爬虫之间的关联
  - sometimes，对一张页面进行请求的时候，如果请求的过程中不携带cookie的话，那么我们是无法请求到正确的页面数据。因此cookie是爬虫中一个非常典型且常见的反爬机制。



**session总结：**

- cookie其实是不安全的（保存在客户端），所以有了session机制。简单来说（每个框架都不一样，这只是举一个通用的实现策略），整过过程是这样：
  - 服务器根据用户名和密码，生成一个session ID，存储到服务器的数据库中。
  - 用户登录访问时，服务器会将对应的session ID发送给用户（本地浏览器）。
  - 浏览器会将这个session ID存储到cookie中，作为一个键值项。
  - 以后，浏览器每次请求，就会将含有session ID的cookie信息，一起发送给服务器。
  - 服务器收到请求之后，通过cookie中的session ID，到数据库中去查询，解析出对应的用户名，就知道是哪个用户的请求了。





### 10.1.2 requests库中的Cookie

​	雪球网链接：https://xueqiu.com/

​	以爬取雪球网中的咨询信息为例，这个网站需要不需要登陆，但会检查用户的Cookie信息。

```python
import requests

# 伪装头信息
headers = {
    'User-Agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.149 Safari/537.36'
}
# 链接
base_url = 'https://xueqiu.com/statuses/hot/listV2.json?since_id=-1&max_id=204892&size=15'
# 请求数据
response = requests.get(url=base_url,headers=headers)
# 解析数据
data = response.json()
# 输出数据
print(data)
# {'error_description': '遇到错误，请刷新页面或者重新登录帐号后再试', 'error_uri': '/statuses/hot/listV2.json', 'error_data': None, 'error_code': '400016'}
```

​	我们必须要携带cookie信息去发送请求。

**方式一：手动处理**

- 将抓包工具中的cookie粘贴在headers中

  <img src="C:\Users\ACG1314\AppData\Roaming\Typora\typora-user-images\image-20220510132755734.png" alt="image-20220510132755734" style="zoom:50%;" />

- 弊端：cookie如果过了有效时长则该方式失效。

```python
import requests

# 伪装头信息（UA和COOKIE）
headers = {
    'User-Agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.149 Safari/537.36',
    'Cookie': 'acw_tc=2760779516521603839277537e87b6cf0cadf53f228fe223f044318536563f; xq_a_token=e8119f7d7a050cdbfa822fa0da4de5bec1ee0dc7; xqat=e8119f7d7a050cdbfa822fa0da4de5bec1ee0dc7; xq_r_token=bab125594aab3ef313d5a620a0e9aa1dc69c42bb; xq_id_token=eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiJ9.eyJ1aWQiOi0xLCJpc3MiOiJ1YyIsImV4cCI6MTY1NDAzOTczMSwiY3RtIjoxNjUyMTYwMzMxOTA3LCJjaWQiOiJkOWQwbjRBWnVwIn0.Miqh4K0L5Tb8MHqhOa2X-kgsGTOIvlW_kZDEZWZndzFIczhI60diL6PIVePBM0qj2Ni1xUwhKjTxunY6MV56ZRuwoa5tDiaeHslZJ7sygPoh4sPry48LIaREb_Tv1-7aYSVTAPHpHT0aWVVl9V_Pku0E3g9hkzD1vyDGAf6LdpwZs8eTus8RgXOLG97KcfVSgpUK3Q_69ZBTyhwIekoP84RN5LHs0I8NrC-FV76da66Fjtkw4iSOD6G9-06CkFxJPlYbHxiUYYvYwkaA0dKbm48NuhhaMa3Y0LJSZUwIjXWEmVYO1wUXiyfy0EfqcHYX_x8AlwXZDhCg229_FhiCCA; u=881652160383936; device_id=908ce3d970c4c7f89cf7b27680bd34ba; Hm_lvt_1db88642e346389874251b5a1eded6e3=1652160385; Hm_lpvt_1db88642e346389874251b5a1eded6e3=1652160390'
}
# 链接
base_url = 'https://xueqiu.com/statuses/hot/listV2.json?since_id=-1&max_id=346797&size=15'
# 请求数据
response = requests.get(url=base_url,headers=headers)
# 解析数据
data = response.json()
# 输出数据
print(data)
```

![image-20220510133131729](C:\Users\ACG1314\AppData\Roaming\Typora\typora-user-images\image-20220510133131729.png)





**方式2：自动处理(重点)**

- 基于Session对象实现自动处理。
- 如何获取一个session对象：requests.Session()返回一个session对象。
- session对象的作用：
  - 该对象可以向requests一样调用get和post发起指定的请求。只不过如果在使用session发请求的过程中如果产生了cookie，则cookie会被自动存储到该session对象中，那么就意味着下次再次使用session对象发起请求，则该次请求就是携带cookie进行的请求发送。
- 在爬虫中使用session的时候，session对象至少会被使用几次？
  - 两次。第一次使用session是为了将cookie捕获且存储到session对象中。下次的时候就是携带cookie进行的请求发送。

```python
import requests

# 伪装头信息（UA和COOKIE）
headers = {
    'User-Agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.149 Safari/537.36'
}
# 首页链接
ori_url = 'https://xueqiu.com/'
# Ajax链接
base_url = 'https://xueqiu.com/statuses/hot/listV2.json?since_id=-1&max_id=346797&size=15'

# 创建一个Session对象
session = requests.Session()
print(session.cookies)
# <RequestsCookieJar[]>
# 用Session对象向首页发送第一次请求（目的：获取cookie）
session.get(url=ori_url,headers=headers)
print(session.cookies)
# <RequestsCookieJar[<Cookie u=681652160960616 for .xueqiu.com/>, <Cookie xq_a_token=e8119f7............
# 用Session对象向目标数据发送第二次请求（目的：获取数据）
response = session.get(url=base_url,headers=headers)

# 解析数据
data = response.json()
# 输出数据
print(data)
```

<img src="C:\Users\ACG1314\AppData\Roaming\Typora\typora-user-images\image-20220510133708502.png" alt="image-20220510133708502" style="zoom: 120%;" />

### 10.1.3 Session进行模拟登陆

#### 实训一：Session模拟登陆

测试网站【https://login2.scrape.center/login】

测试用户【用户名：`admin`  密码：`admin` 】

​		登陆界面：

<img src="C:\Users\ACG1314\AppData\Roaming\Typora\typora-user-images\image-20220510161844043.png" alt="image-20220510161844043" style="zoom:50%;" />

​		登陆后进入：

<img src="C:\Users\ACG1314\AppData\Roaming\Typora\typora-user-images\image-20220510162009545.png" alt="image-20220510162009545" style="zoom: 50%;" />



​	首先我们来分析登陆的请求，进入登陆界面，打开抓包工具，清空历史，得到如下：

<img src="C:\Users\ACG1314\AppData\Roaming\Typora\typora-user-images\image-20220510161316940.png" alt="image-20220510161316940" style="zoom:67%;" />



​		点击【Preserve log】

<img src="C:\Users\ACG1314\AppData\Roaming\Typora\typora-user-images\image-20220510161403174.png" alt="image-20220510161403174" style="zoom:67%;" />



​	在登陆界面上随便输入用户名和密码，并点击登陆

<img src="C:\Users\ACG1314\AppData\Roaming\Typora\typora-user-images\image-20220510162143424.png" alt="image-20220510162143424" style="zoom: 50%;" />

​	这个请求包就是用于向服务器发起登陆请求的包，这是个POST请求，POST表单有两个值。

![image-20220510162217463](C:\Users\ACG1314\AppData\Roaming\Typora\typora-user-images\image-20220510162217463.png)

![image-20220510162227533](C:\Users\ACG1314\AppData\Roaming\Typora\typora-user-images\image-20220510162227533.png)



​	分析结束后，我们得到结论。

1. 首先创建一个Session对象，向实际的登陆请求链接【https://login2.scrape.center/login】发起第一次请求，目的是为了获取Cookie。

2. 接着，用该Session对象向目标数据连接【https://login2.scrape.center/】发起第二次请求，目的是为了获取数据。


​	根据以上结论，编写如下代码：

```python
# -*- coding: utf-8 -*-
""" 
    Session和Cookie模拟登陆
"""
import requests
from bs4 import BeautifulSoup
import redis
import re


# 1.准备工作
# 链接
base_url = 'https://login2.scrape.center/'
login_url = 'https://login2.scrape.center/login'

# 头信息
headers = {
    'User-Agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.149 Safari/537.36'
}

# 登陆表单
data = {
    'username': 'admin',
    'password': 'admin'
}

# 连接redis数据库
r = redis.Redis(host="127.0.0.1",port=6379,password=None,db=1)

# 创建一个Session对象
session = requests.Session()

# 2.发起请求
# 第一次请求：目的是为了获取Cookie
session.post(url=login_url,data=data,headers=headers)

# 第二次请求：目的是为了获取数据
# ps:这里有分页规则，有能力的同学可以补充分页
response = session.get(url=base_url,headers=headers)

# 文本
text = response.text

# 3.解析数据
# bs实例化
soup = BeautifulSoup(text,'lxml')

# 找到所有div
div_ls = soup.find_all(name="div",class_= re.compile("el-card item m-t is-hover-shadow"))

# 遍历div
for div in div_ls:
    # 标题
    title = div.find(name='h2',attrs={'class':"m-b-sm"}).get_text()

    # 评分
    score = div.find(name="p",class_= re.compile("score m-t-md m-b-n-sm")).get_text()

    # 4.持久化存储
    r.set(name=title,value=score)

    # 提示
    print("{}已获取".format(title))

# 结束
print("结束")
```



## 10.2 基于JWT的模拟登陆

​	现在有很多网站采取的开发模式是前后端分离式，所以使用JWT进行登陆校验越来越普遍。在请求数据时，服务器会校验请求中携带JWT是否有效，如果有效，就返回正常的数据。

​	在这种模式下，爬虫的目的就是为了获取JWT。

### 10.2.1 JWT原理（了解）

参考链接：https://blog.csdn.net/weixin_45070175/article/details/118559272

​	Web开发技术一直在发展，近几年前后端分离的开发模式越来越火，传统的基于Session和Cookie的校验又存在一定问题。

​	例如服务器需要维护登陆用户的Session信息，而且分布式部署也不方便，不太适合前后端分离的项目，所以JWT技术应运而生。

​	JWT的英文全称为JSON Web Token，是为了在网络应用环境中传递声明而执行的一种基于JSON的开放标准，实际上就是在每次登陆时都通过一个Token字段校验登陆状态。

​	JWT的声明一般用来在身份提供者和服务提供者之间传递要认证的用户身份信息，以便从资源服务器中获取资源，此外可以增加一些业务逻辑必须的声明信息。

​	总之Token可以直接用于认证，也可以传递一些额外信息。

​	有了JWT，一些认证就不需要借助于Session和Cookie了，服务器也无需维护Session信息，从而减少了开销，只需要有一个校验JWT的功能就够了，同时还支持分布式部署和跨语言开发。



![image-20220510173612462](C:\Users\ACG1314\AppData\Roaming\Typora\typora-user-images\image-20220510173612462.png)



1. 首先，前端通过Web表单将自己的用户名和密码发送到后端的接口，这个过程一般是一个POST请求。建议的方式是通过SSL加密的传输(HTTPS)，从而避免敏感信息被嗅探

2. 后端核对用户名和密码成功后，将包含用户信息的数据作为JWT的Payload，将其与JWT Header分别进行Base64编码拼接后签名，形成一个JWT Token，形成的JWT Token就是一个如同lll.zzz.xxx的字符串
3. 后端将JWT Token字符串作为登录成功的结果返回给前端。前端可以将返回的结果保存在浏览器中，退出登录时删除保存的JWT Token即可
4. 前端在每次请求时将JWT Token放入HTTP请求头中的Authorization属性中(解决XSS和XSRF问题)
5. 后端检查前端传过来的JWT Token，验证其有效性，比如检查签名是否正确、是否过期、token的接收方是否是自己等等
6. 验证通过后，后端解析出JWT Token中包含的用户信息，进行其他逻辑操作(一般是根据用户信息得到权限等)，返回结果



**JWT结构**

​	JWT由3部分组成：标头([Header](https://so.csdn.net/so/search?q=Header&spm=1001.2101.3001.7020))、有效载荷(Payload)和签名(Signature)。在传输的时候，会将JWT的3部分分别进行Base64编码后用`.`进行连接形成最终传输的字符串
$$
JWTString=Base64(Header).Base64(Payload).HMACSHA256(base64UrlEncode(header)+"."+base64UrlEncode(payload),secret)
$$


![image-20220510174343095](C:\Users\ACG1314\AppData\Roaming\Typora\typora-user-images\image-20220510174343095.png)

#### 1.Header

​	**JWT头**是一个描述JWT元数据的JSON对象，alg属性表示签名使用的算法，默认为HMAC SHA256（写为HS256）；typ属性表示令牌的类型，JWT令牌统一写为JWT。最后，使用Base64 URL算法将上述JSON对象转换为字符串保存

```python
{
  "alg": "HS256",
  "typ": "JWT"
}
```

#### 2.Payload

​	**有效载荷**部分，是JWT的主体内容部分，也是一个**JSON对象**，包含需要传递的数据。 JWT指定七个默认字段供选择

```python
iss：发行人
exp：到期时间
sub：主题
aud：用户
nbf：在此之前不可用
iat：发布时间
jti：JWT ID用于标识该JWT
```

​	这些预定义的字段并不要求强制使用。除以上默认字段外，我们还可以自定义私有字段，**一般会把包含用户信息的数据放到payload中**，如下例：

```python
{
  "sub": "1234567890",
  "name": "Helen",
  "admin": true
}
```



```
	请注意，默认情况下JWT是未加密的，因为只是采用base64算法，拿到JWT字符串后可以转换回原本的JSON数据，任何人都可以解读其内容，因此不要构建隐私信息字段，比如用户的密码一定不能保存到JWT中，以防止信息泄露。JWT只是适合在网络中传输一些非敏感的信息
```



#### 3.Signature

​	签名哈希部分是对上面两部分数据签名，需要使用base64编码后的header和payload数据，通过指定的算法生成哈希，以确保数据不会被篡改。首先，需要指定一个密钥（secret）。该密码仅仅为保存在服务器中，并且不能向用户公开。然后，使用header中指定的签名算法（默认情况下为HMAC SHA256）根据以下公式生成签名
$$
HMACSHA256(base64UrlEncode(header)+"."+base64UrlEncode(payload),secret)
$$


在计算出签名哈希后，JWT头，有效载荷和签名哈希的三个部分组合成一个字符串，每个部分用`.`分隔，就构成整个JWT对象

![image-20220510174844644](C:\Users\ACG1314\AppData\Roaming\Typora\typora-user-images\image-20220510174844644.png)

```
	注意JWT每部分的作用，在服务端接收到客户端发送过来的JWT token之后：

	header和payload可以直接利用base64解码出原文，从header中获取哈希签名的算法，从payload中获取有效数据
	
	signature由于使用了不可逆的加密算法，无法解码出原文，它的作用是校验token有没有被篡改。服务端获取header中的加密算法之后，利用该算法加上secretKey对header、payload进行加密，比对加密后的数据和客户端发送过来的是否一致。注意secretKey只能保存在服务端，而且对于不同的加密算法其含义有所不同，一般对于MD5类型的摘要加密算法，secretKey实际上代表的是盐值

```



### 10.2.2 JWT机制模拟登陆

#### 实训二：JWT模拟登陆

测试网站：https://login3.scrape.center/login

<img src="C:\Users\ACG1314\AppData\Roaming\Typora\typora-user-images\image-20220510175402033.png" alt="image-20220510175402033" style="zoom:50%;" />



和**10.1.3**一样打开开发者工具，抓包请求数据（这里输入正确的账户密码）

<img src="C:\Users\ACG1314\AppData\Roaming\Typora\typora-user-images\image-20220510175518236.png" alt="image-20220510175518236" style="zoom: 50%;" />



抓取到请求的数据包

![image-20220510175630698](C:\Users\ACG1314\AppData\Roaming\Typora\typora-user-images\image-20220510175630698.png)

<img src="C:\Users\ACG1314\AppData\Roaming\Typora\typora-user-images\image-20220510175646255.png" alt="image-20220510175646255" style="zoom:150%;" />

我们发现得到的返回内容是一个`token`字段的JSON数据，这就是我们要获取**JWT**。

![image-20220510175759277](C:\Users\ACG1314\AppData\Roaming\Typora\typora-user-images\image-20220510175759277.png)



```python
{"token":"eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJ1c2VyX2lkIjoxLCJ1c2VybmFtZSI6ImFkbWluIiwiZXhwIjoxNjUyMjE5NzM2LCJlbWFpbCI6ImFkbWluQGFkbWluLmNvbSIsIm9yaWdfaWF0IjoxNjUyMTc2NTM2fQ.5mT_t7_BJHJVr-2TYolco2-O6vKS2yU-P2EY8kpQEPc"}
```



我们找到包含数据的Ajax数据包：

![image-20220510180055854](C:\Users\ACG1314\AppData\Roaming\Typora\typora-user-images\image-20220510180055854.png)



![image-20220510180111180](C:\Users\ACG1314\AppData\Roaming\Typora\typora-user-images\image-20220510180111180.png)

我们回去查看一下头信息，就会发现，在`Request Headers`中新加了一条字段 `Authorization`

![image-20220510202152792](C:\Users\ACG1314\AppData\Roaming\Typora\typora-user-images\image-20220510202152792.png)



​	这个字段就是我们通过登陆网站后服务器返回给我们的JWT，也就是我们第一次请求获取的返回数据。



那么现在，我们要做的JWT模拟登陆的整个思路就变得非常简单了，可以简单分为以下两个步骤：

1. 模拟登陆请求，带上必要的登陆信息，获取返回的JWT
2. 之后发送请求时，在请求头中加入`Authorization`字段，值就是JWT对应的内容

```python
# -*- coding: utf-8 -*-
""" 
    JWT模拟登陆
"""
import requests
from urllib.parse import urljoin
import logging  # 日志模块

# 1.准备工作
# 链接
BASE_URL = 'https://login3.scrape.center/'
# LOGIN_URL = urljoin(BASE_URL,"/api/login")
# INDEX_URL = urljoin(BASE_URL,"/api/book")
LOGIN_URL = 'https://login3.scrape.center/api/login'
INDEX_URL = 'https://login3.scrape.center/api/book'

# 用户名和密码
USERNAME = "admin"
PASSWORD = "admin"

# 书籍列表
book_ls = []

# # 开始日志记录
# 将日志记录在文件中
# logging.basicConfig(level=logging.DEBUG, format='%(asctime)s %(message)s',filename="mySpider.log")
# 将日志输出到控制台上
logging.basicConfig(level=logging.DEBUG, format='%(asctime)s %(message)s')
logging.info("start my book spider ！！！")

# 2.发送请求
# 发送第一次请求，目的：为了获取JWT
response_login = requests.post(url=LOGIN_URL, data={"username":USERNAME, "password":PASSWORD})
# JSON数据
json_data_login = response_login.json()
print("Response JSON : ", json_data_login)

if json_data_login.get("token") is None:
    logging.error("登陆失败")
    assert False, '登陆失败'
else:
    logging.info("登陆成功")

# JWT
JWT = json_data_login.get("token")
print("JWT : ", JWT)

# 携带JWT的头信息
headers = {
    "Authorization":"jwt {}".format(JWT)
}

# 发送第二次请求，目的：为了获取数据

# GET参数
params = {
    'limit':'18',
    'offset':None
}

for page in range(1, 11):
    # 更新GET参数
    params.update(
        {
            "offset":(page - 1) * 18
        }
    )

    # 发送请求
    response_index = requests.get(url=INDEX_URL, params=params, headers=headers)
    # 提取json数据
    json_data = response_index.json()

    # 3. 数据解析
    # 获取results列表
    results = json_data.get('results')

    # 遍历
    for result in results:
        # ID
        id = result.get('id')
        # 片名
        name = result.get("name")
        # 评分
        score = result.get("score")
        # 作者
        authors_ls = result.get("authors")
        authors = '\t\t'.join(authors_ls) if authors_ls is not None else str(authors_ls)
        # 添加数据
        book_ls.append(
            {
                "ID":id,
                "片名":name,
                "评分":score,
                "作者":authors,
            }
        )

        # 提醒
        logging.info("已添加编号{}的电影{}".format(id, name))

# 结束
logging.info("     End ！！！    ")

# 输出最终结果 -- 请同学们自己修改为持久化存储
print(book_ls)
```

​	在原来的爬虫实训中，我们是通过`print()`输出提示。在我们本次实训中，加入了`logging模块`，这是用于日志的模块，我们在实际工作中，用的也是日志方法作为提示。

## 10.3 验证码识别（持续更新中）

​	各类网络采用了各种各样的措施反爬虫，其中一个便是验证码。我们在日常网站登陆的时候也会发现，现在不是简简单单输入账号密码就行了，往往也会加入验证码。比如我们在登陆职教云的时候，就要输入一个数字验证码才能登陆。



<img src="C:\Users\ACG1314\AppData\Roaming\Typora\typora-user-images\image-20220511113303050.png" alt="image-20220511113303050" style="zoom:67%;" />

​	而且现在的验证码花样越来越多，由最初只是几个数字组合而成的简单图形，发展到了英文字母和混淆曲线，还有一些网站使用中文字符验证码，有个甚至加入了滑动验证码，点击验证码，问题验证码，这无疑使得识别变得愈发困难。

​	如下是豆瓣的滑动验证码：

![image-20220511113718702](C:\Users\ACG1314\AppData\Roaming\Typora\typora-user-images\image-20220511113718702.png)



​	验证码是为了检验操作者是否为人，一定程度上制约了爬虫的发展。但随着时代的进步，人工智能的发展达到最热门的程度，我们可以通过人工智能的方法来解决验证码的问题，用"人工"的智能来代替"人"的智能解决验证码的问题。

### 10.3.1 打码平台识别验证码

​	首先，我们来介绍一个最简单的办法，就是用到网上成熟的打码平台。利用打码平台可以轻松识别各种各样的验证码，图像验证码，滑动验证码，点选验证码和逻辑推理验证码都不在话下，而且不需要懂任何人工智能算法，以及维护任何模型和服务。

​	打码平台提供了一系列API，只需要向API上传验证码图片，它编号返回对应的识别结果。

​	其实打码平台一般是半自动化的，也就是平台背后既有识别算法、模型的支持，也有人工打码的支持。

​	现在网上的打码平台是非常多，比如百度，阿里都有打码的API，这里我比较推荐的是其中一个打码平台超级鹰【http://www.chaojiying.com/】，它能识别的验证码是比较广泛的，识别效果也很不错。

<img src="C:\Users\ACG1314\AppData\Roaming\Typora\typora-user-images\image-20220511115943629.png" alt="image-20220511115943629" style="zoom: 50%;" />

​	当然，打码平台一般都是是需要付费的，以超级鹰平台为例：1元可以识别100个验证码左右

<img src="C:\Users\ACG1314\AppData\Roaming\Typora\typora-user-images\image-20220511120107626.png" alt="image-20220511120107626" style="zoom: 50%;" />



​		我们可以在官网提供的开发文档中，找到API的开发文档。

<img src="C:\Users\ACG1314\AppData\Roaming\Typora\typora-user-images\image-20220511120647445.png" alt="image-20220511120647445" style="zoom: 67%;" />

​		

​	

​	接下来就可以根据开发文档提供的代码完成验证码的识别，我们以实训三为例进行一个图形验证码的识别。

### 

​	**第一步：注册用户（略）**

<img src="C:\Users\ACG1314\AppData\Roaming\Typora\typora-user-images\image-20220511121542017.png" alt="image-20220511121542017" style="zoom:50%;" />



​	**第二步：生成软件ID**	

​	![image-20220511121938630](C:\Users\ACG1314\AppData\Roaming\Typora\typora-user-images\image-20220511121938630.png)

​	

① 在用户中心中生成一个用于接入接口的软件ID

![image-20220512102712023](C:\Users\ACG1314\AppData\Roaming\Typora\typora-user-images\image-20220512102712023.png)

<img src="C:\Users\ACG1314\AppData\Roaming\Typora\typora-user-images\image-20220512102743680.png" alt="image-20220512102743680" style="zoom:50%;" />



![image-20220512102859430](C:\Users\ACG1314\AppData\Roaming\Typora\typora-user-images\image-20220512102859430.png)

![image-20220512102936680](C:\Users\ACG1314\AppData\Roaming\Typora\typora-user-images\image-20220512102936680.png)



![image-20220512103011144](C:\Users\ACG1314\AppData\Roaming\Typora\typora-user-images\image-20220512103011144.png)



​	**第三步：查看开发文档**	

① 选择你的开发语言（Python为例）

![image-20220512103111247](C:\Users\ACG1314\AppData\Roaming\Typora\typora-user-images\image-20220512103111247.png)



② 下载开发文档

![image-20220512103147176](C:\Users\ACG1314\AppData\Roaming\Typora\typora-user-images\image-20220512103147176.png)



![image-20220512103242962](C:\Users\ACG1314\AppData\Roaming\Typora\typora-user-images\image-20220512103242962.png)



![image-20220512103258732](C:\Users\ACG1314\AppData\Roaming\Typora\typora-user-images\image-20220512103258732.png)



③ 参考【readme.txt】使用示例代码【chaojiying.py】

​	示例代码

```python
#!/usr/bin/env python
# coding:utf-8

import requests
from hashlib import md5

class Chaojiying_Client(object):

    def __init__(self, username, password, soft_id):
        self.username = username
        password =  password.encode('utf8')
        self.password = md5(password).hexdigest()
        self.soft_id = soft_id
        self.base_params = {
            'user': self.username,
            'pass2': self.password,
            'softid': self.soft_id,
        }
        self.headers = {
            'Connection': 'Keep-Alive',
            'User-Agent': 'Mozilla/4.0 (compatible; MSIE 8.0; Windows NT 5.1; Trident/4.0)',
        }

    def PostPic(self, im, codetype):
        """
        im: 图片字节
        codetype: 题目类型 参考 http://www.chaojiying.com/price.html
        """
        params = {
            'codetype': codetype,
        }
        params.update(self.base_params)
        files = {'userfile': ('ccc.jpg', im)}
        r = requests.post('http://upload.chaojiying.net/Upload/Processing.php', data=params, files=files, headers=self.headers)
        return r.json()

    def PostPic_base64(self, base64_str, codetype):
        """
        im: 图片字节
        codetype: 题目类型 参考 http://www.chaojiying.com/price.html
        """
        params = {
            'codetype': codetype,
            'file_base64':base64_str
        }
        params.update(self.base_params)
        r = requests.post('http://upload.chaojiying.net/Upload/Processing.php', data=params, headers=self.headers)
        return r.json()

    def ReportError(self, im_id):
        """
        im_id:报错题目的图片ID
        """
        params = {
            'id': im_id,
        }
        params.update(self.base_params)
        r = requests.post('http://upload.chaojiying.net/Upload/ReportError.php', data=params, headers=self.headers)
        return r.json()


if __name__ == '__main__':
    chaojiying = Chaojiying_Client('超级鹰用户名', '超级鹰用户名的密码', '96001')	#用户中心>>软件ID 生成一个替换 96001
    im = open('a.jpg', 'rb').read()													#本地图片文件路径 来替换 a.jpg 有时WIN系统须要//
    print(chaojiying.PostPic(im, 1902))											#1902 验证码类型  官方网站>>价格体系 3.4+版 print 后要加()
    # print(chaojiying.PostPic(base64_str, 1902))  #此处为传入 base64代码

```

​	将标红的地方根据自己的需要进行修改。

![image-20220512104455409](C:\Users\ACG1314\AppData\Roaming\Typora\typora-user-images\image-20220512104455409.png)

​	验证码类型设置：

<img src="C:\Users\ACG1314\AppData\Roaming\Typora\typora-user-images\image-20220512104604700.png" alt="image-20220512104604700" style="zoom:67%;" />



示例图片：

![image-20220512104624674](C:\Users\ACG1314\AppData\Roaming\Typora\typora-user-images\image-20220512104624674.png)



展示结果：

![image-20220512104728985](C:\Users\ACG1314\AppData\Roaming\Typora\typora-user-images\image-20220512104728985.png)



#### 实训三：带验证码的模拟登陆

测试网站：https://so.gushiwen.cn/user/login.aspx?

测试用户【用户名：`hfv27215@zcrcd.com`   密码：`123456`】

<img src="C:\Users\ACG1314\AppData\Roaming\Typora\typora-user-images\image-20220512132328295.png" alt="image-20220512132328295" style="zoom: 67%;" />



登录后才能查看【我的收藏】https://so.gushiwen.cn/user/collect.aspx?

<img src="C:\Users\ACG1314\AppData\Roaming\Typora\typora-user-images\image-20220512133854422.png" alt="image-20220512133854422" style="zoom:67%;" />

​	

创建如下的目录结构，将超级鹰的示例代码复制到**chaojiying.py**中

![image-20220512125215861](C:\Users\ACG1314\AppData\Roaming\Typora\typora-user-images\image-20220512125215861.png)



编写**mySpider.py**

​	

​	准备工作：

```python
# 头信息
headers = {
    'User-Agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.149 Safari/537.36'
}

# 登陆首页链接
LOGIN_INDEX_URL = "https://so.gushiwen.cn/user/login.aspx?"
# 收藏链接
COLLECT_URL = "https://so.gushiwen.cn/user/collect.aspx?"
```

​	

​	首先，我们要创建一个Session对象，用来保存前次访问的状态。

```python
# 1.1 创建一个Session对象
session = requests.Session()
```

​	

​	其次，我们得访问首页https://so.gushiwen.cn/user/login.aspx?，将验证码图片保存到本地

<img src="C:\Users\ACG1314\AppData\Roaming\Typora\typora-user-images\image-20220512134020395.png" alt="image-20220512134020395" style="zoom: 50%;" />

```python
# 1.2 下载验证码
# 获取首页并etree实例化
login_response = session.get(url=LOGIN_INDEX_URL, headers=headers)
text = login_response.text
login_tree = etree.HTML(text)
# 找验证码的链接
img_src = 'https://so.gushiwen.cn/' + ''.join(login_tree.xpath('//*[@id="imgCode"]/@src'))
# 请求验证码数据
img = session.get(url=img_src, headers=headers).content
# 保存验证码图片
with open("./captcha/cap.png",'wb') as fp:
    fp.write(img)
```



​	通过超级鹰模型识别验证码

```python
# 1.3 通过超级鹰识别验证码
chaojiying = Chaojiying_Client('超级鹰用户名', '超级鹰用户名密码', '软件ID')	#用户中心>>软件ID 生成一个替换 96001
im = open('./captcha/cap.png', 'rb').read()			#本地图片文件路径 来替换 a.jpg 有时WIN系统须要//
# print(chaojiying.PostPic(im, 1902))			#1902 验证码类型  官方网站>>价格体系 3.4+版 print 后要加()
# 验证码值
captcha = chaojiying.PostPic(im, 1902).get('pic_str')
```





​	识别完验证码后，通过开发者工具找到登陆链接为https://so.gushiwen.cn/user/login.aspx?

<img src="C:\Users\ACG1314\AppData\Roaming\Typora\typora-user-images\image-20220512134907806.png" alt="image-20220512134907806" style="zoom: 67%;" />

![image-20220512142523108](C:\Users\ACG1314\AppData\Roaming\Typora\typora-user-images\image-20220512142523108.png)

```python
# 1.4 登陆古诗文网
# 登陆链接
LOGIN_URL = "https://so.gushiwen.cn/user/login.aspx?"
# post表单
data = {
    "from": "http://so.gushiwen.cn/user/collect.aspx",
    "email": "hfv27215@zcrcd.com",
    "pwd": "123456",
    "code": captcha,
}
# 发送登陆请求,目的：为了获取Cookie
session.post(url=LOGIN_URL,data=data,headers=headers)
```



​	当得到了登陆状态的cookie后，我们就可以去访问【我的收藏】了：

```python
# 1.5 请求收藏链接，获取收藏数据
response = session.get(url=COLLECT_URL,headers=headers)
collect_tree = etree.HTML(response.text)
# 这里简单输出一下结果
print(collect_tree.xpath('//*[@id="mainSearch"]/div[2]/div/div/a/text()'))
```



#### 实训三完整代码

```python
import requests
from lxml import etree

from chaojiying import Chaojiying_Client


# 头信息
headers = {
    'User-Agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.149 Safari/537.36'
}

# 登陆首页链接
LOGIN_INDEX_URL = "https://so.gushiwen.cn/user/login.aspx?"
# 登陆链接
LOGIN_URL = "https://so.gushiwen.cn/user/login.aspx?"
# 收藏链接
COLLECT_URL = "https://so.gushiwen.cn/user/collect.aspx?"



# 一、获取登陆状态

# 1.1 创建一个Session对象
session = requests.Session()

# 1.2 下载验证码
# 获取首页并etree实例化
login_response = session.get(url=LOGIN_INDEX_URL, headers=headers)
text = login_response.text
login_tree = etree.HTML(text)
# 找验证码的链接
img_src = 'https://so.gushiwen.cn/' + ''.join(login_tree.xpath('//*[@id="imgCode"]/@src'))
# 请求验证码数据
img = session.get(url=img_src, headers=headers).content
# 保存验证码图片
with open("./captcha/cap.png",'wb') as fp:
    fp.write(img)

# 1.3 通过超级鹰识别验证码
chaojiying = Chaojiying_Client('超级鹰用户名', '超级鹰用户名密码', '软件ID')	#用户中心>>软件ID 生成一个替换 96001
im = open('./captcha/cap.png', 'rb').read()			#本地图片文件路径 来替换 a.jpg 有时WIN系统须要//
# print(chaojiying.PostPic(im, 1902))		#1902 验证码类型  官方网站>>价格体系 3.4+版 print 后要加()
# 验证码值
captcha = chaojiying.PostPic(im, 1902).get('pic_str')

# 1.4 登陆古诗文网
# post表单
data = {
    "from": "http://so.gushiwen.cn/user/collect.aspx",
    "email": "hfv27215@zcrcd.com",
    "pwd": "123456",
    "code": captcha,
}
# 发送登陆请求,目的：为了获取Cookie
session.post(url=LOGIN_URL,data=data,headers=headers)


# 1.5 请求收藏链接，获取收藏数据
response = session.get(url=COLLECT_URL,headers=headers)
collect_tree = etree.HTML(response.text)
# 这里简单输出一下结果
print(collect_tree.xpath('//*[@id="mainSearch"]/div[2]/div/div/a/text()'))
```

<img src="C:\Users\ACG1314\AppData\Roaming\Typora\typora-user-images\image-20220512141045037.png" alt="image-20220512141045037" style="zoom: 67%;" />



​	面对对象写法

```python
EMAIL = 'hfv27215@zcrcd.com'
PWD = '123456'

import requests
from lxml import etree

from chaojiying import Chaojiying_Client


class GushiwenSpider(object):
    '''
    获取《我的收藏》的收藏列表
    '''

    def __init__(self):
        '''
        init   ==  我们以前一直在说的准备工作
        '''
        # self --- this
        # 登陆首页
        self.login_index_url = 'https://so.gushiwen.cn/user/login.aspx?'
        # 登陆链接
        self.login_url = 'https://so.gushiwen.cn/user/login.aspx?'
        # 登陆表单
        self.data = {
            'from': 'http://so.gushiwen.cn/user/collect.aspx',
            'email': '',
            'pwd': '',
            'code': ''
        }
        # 头信息  单独设置 set_headers()
        # self.headers = {}    -- 通过 setter()方法设置属性值
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/65.0.3325.146 Safari/537.36'
        }

        # session类
        # 保留上一次访问的状态
        self.session = requests.Session()

        # 创建一个验证码识别类型
        self.chaojiying = Chaojiying_Client('acg1314', 'Qlj244304463', '933350')

        # 《我的收藏》链接，即目标数据链接
        self.collect_url = 'https://so.gushiwen.cn/user/collect.aspx'

    # 运行方法
    def run(self):
        # 第一次登陆请求
        self.login()
        # 第二次爬取请求
        # <generator object GushiwenSpider.crawel_movie at 0x0000000003734410>  --> 可迭代类型  --> 列表
        # 生成器
        results = self.crawel_movie()

        # 打印结果
        # 强制转型成list类型
        print(results)
        # print(list(results))
        for result in results:
            print(result)

    # 第一次请求，目的是为了获取登陆状态
    def login(self):
        '''
        登陆请求，目的是为了获取登陆状态 -- cookie  或者 是为了获取 token
        :return:  None
        '''

        # 设置账户密码
        self.set_email_pwd()
        # 设置验证码
        self.set_code()
        # print(self.data)

        # 发起登陆请求,session能保存登陆请求后的cookie
        self.session.post(url=self.login_url, data=self.data, headers=self.headers)

        return None

    # 第二次请求，爬取数据链接
    def crawel_movie(self):
        '''
        请求目标链接
        :return: 目标数据
        '''
        response = self.session.get(url=self.collect_url, headers=self.headers)
        text = response.text
        tree = etree.HTML(text)
        my_fav_ls = tree.xpath('//*[@id="mainSearch"]/div[2]/div/div/a/text()')
        # print(my_fav_ls)
        # 一次性返回整个列表
        # return my_fav_ls

        # 将一次一次的返回列表里面的值，并且是一个整体性的返回
        for my_fav in my_fav_ls:
            # 一个一个的返回，但是return就代表函数结束，return显然是做不到这个事情的
            # return my_fav
            yield my_fav

    def chaojiying_shibie(self, img_path):
        # 识别的图片都是本地的图片  --》  第一步：把验证码下载到本地   第二步：通过xx方法识别本地的验证
        im = open(img_path, 'rb').read()  # 本地图片文件路径 来替换 a.jpg 有时WIN系统须要//
        return self.chaojiying.PostPic(im, 1902).get('pic_str')

    def set_email_pwd(self, email=EMAIL, pwd=PWD):
        '''
        设置登陆账户和密码
        :param email: 登录账户
        :param pwd: 密码
        :return: None
        '''
        self.data["email"] = email
        self.data['pwd'] = pwd
        return None

    def set_code(self):
        '''
        设置验证码
        :return: None
        '''
        code = self.get_code()  # 怎么获取这个验证码？？？？
        self.data["code"] = code
        return None

    def get_code(self):
        '''
        最难的地方就是如果识别出我们的验证码！！！！
        今天来实现这个功能！！！！
        识别的图片都是本地的图片  --》
                第一步：把验证码下载到本地
                第二步：通过xx方法识别本地的验证
        :return: code
        '''
        # 验证码的本地路径
        img_path = self.get_captcha()

        # 识别验证码
        # 对本地路径的验证码图片进行验证
        code = self.chaojiying_shibie(img_path)
        # print(code)

        return code

    # def get_page(self):

    def get_captcha(self):
        '''
        下载验证码到本地
        ① GET请求登陆首页
        ② 数据解析（re，xpath，bs4），解析到验证码的链接
        ③ 请求验证码图片链接
        ④ 下载验证码到本地
        :return: 验证码的本地路径
        '''
        response = self.session.get(url=self.login_index_url, headers=self.headers)
        text = response.text
        tree = etree.HTML(text)
        # 在线图片的链接
        img_src = 'https://so.gushiwen.cn' + tree.xpath('//*[@id="imgCode"]/@src')[0]
        # print(img_src)
        # 本地保存的路径
        img_path = "./captcha.png"
        # 把图片下载到img_path中
        img = self.session.get(url=img_src, headers=self.headers).content
        # 保存的方法
        with open(img_path, 'wb') as fp:
            fp.write(img)

        # 本地的路径名
        return img_path


# 模块测试
if __name__ == "__main__":
    # 创建一个爬虫类
    gushiwen_spider = GushiwenSpider()
    # 运行爬虫
    gushiwen_spider.run()

```

![image-20220519102318556](C:\Users\ACG1314\AppData\Roaming\Typora\typora-user-images\image-20220519102318556.png)

### 10.3.2 OCR技术识别图形验证码（了解，更新中）

​	**OCR** （Optical Character Recognition，光学字符识别）是指电子设备（例如扫描仪或数码相机）检查纸上打印的字符，通过检测暗、亮的模式确定其形状，然后用字符识别方法将形状翻译成计算机文字的过程；即，针对印刷体字符，采用光学的方式将纸质文档中的文字转换成为黑白点阵的图像文件，并通过识别软件将图像中的文字转换成文本格式，供文字处理软件进一步编辑加工的技术。如何除错或利用辅助信息提高识别正确率，是OCR最重要的课题，ICR（Intelligent Character Recognition）的名词也因此而产生。衡量一个OCR系统性能好坏的主要指标有：拒识率、误识率、识别速度、用户界面的友好性，产品的稳定性，易用性及可行性等。-- 摘自百度百科

​	**OCR**技术一般用于验证比较简单的，没有过多的干扰线和干扰点的，文字也没有大幅度的变形和选择的图形验证码。



**1.准备工作**

​	在本节的学习过程中需要导入`tesserocr`库，这个库的安装相对起来比较复杂，参考【https://segmentfault.com/a/1190000039929696】。

> 为了增大成功安装的几率，推荐使用 Python 3.7 版本。

在 Windows 下，首先需要下载 Tesseract，它为 Tesserocr 提供了支持，下载链接为：http://digi.bib.uni-mannheim.de/tesseract/。

点击进入之后可以看到有各种 exe 的下载列表，在这里可以选择下载 4.0 版本 tesseract-ocr-setup-4.00.00dev.exe，如图所示：

![img](https://qiniu.cuiqingcai.com/o6k97.png)

其中文件名中带有 dev 的为开发版本，不带 dev 的为稳定版本。

下载完成之后双击安装即可，在安装过程中可以勾选上 Additional language data 选项，安装 OCR 识别支持的语言包，这样 OCR 便可以识别多国语言。

![image-20220512145657773](C:\Users\ACG1314\AppData\Roaming\Typora\typora-user-images\image-20220512145657773.png)

复制你的安装路径，我的安装路径 D:\Python\Tesseract-OCR，界面如下：

![img](https://qiniu.cuiqingcai.com/vqr3e.png)

打开我的电脑系统属性 -> 高级 -> 环境变量，把该路径配置到环境变量：

![img](https://qiniu.cuiqingcai.com/gf5ml.png)

然后将下载好的字库放到 Tesseract-OCR 项目的 tessdata 文件夹里面。



接下来再安装 Tesserocr 即可，直接使用 Pip 安装：

```
pip install tesserocr pillow
```



除此之外，还需要安装`Selenium`，`Pillow`，`Numpy`，`retrying`库，用来模拟登陆，处理图像和重试操作。

可以用pip来进行安装

```
pip install selenium
```

```
pip install pillow
```

```
pip install numpy
```

```
pip install retrying
```



### 10.3.3 OpenCV识别滑动验证码（了解）

​	随着互联网技术的发展，各种新型验证码层出不穷，最具有代表性的便是滑动验证码。本节中我们首先了解滑动验证码的验证流程，然后介绍一个简易的利用图像处理技术识别滑动验证码缺口的方法。

![image-20220511113718702](C:\Users\ACG1314\AppData\Roaming\Typora\typora-user-images\image-20220511113718702.png)

​	滑动验证码的下方通常有一个滑轨，上面带有类似"拖动滑块完成拼图"的文字提示，我们需要向右拖拽滑轨上的滑块，这时正上方的滑块会随它一起向右移动。验证码的右侧有一个滑块缺口，我们将滑块恰好移动到这个缺口除，就算验证成功了。

​	在第十二章的学习，我们将学习可以通过模拟浏览器拖拽鼠标的方法。开始的位置的坐标通常为0，那么我们只需要知道缺口处的坐标，就可以完成拖拽了。

​	总结一下，如果我们想用爬虫自动化完成这一流程，关键步骤有两个：

1. **识别目标缺口的位置：本节**
2. **将滑块拖到缺口位置：第十二章**

​	

​	本节的重点目标是识别目标缺口的位置，即给定一张滑动验证码的图片，使用图像处理技术识别出缺口的位置。



**1.基本原理**

​	本节中我们会介绍使用OpenCV技术识别缺口的方法，输入一个带有缺口的验证码图片，输出缺口位置（一般是缺口的横坐标）。

​	比如下面这一张带入缺口的验证码图片

![image-20220512164114368](C:\Users\ACG1314\AppData\Roaming\Typora\typora-user-images\image-20220512164114368.png)



​	具体的步骤为：

​	（1）对验证码图片进行高斯模糊滤波处理，消除部分噪声干扰。

​				原理：https://blog.csdn.net/weixin_51571728/article/details/121527964

​	（2）利用边缘检测算法，通过调整相应阈值识别出验证码图片中滑块的编译。

​				原理：https://zhuanlan.zhihu.com/p/398939598

​	（3）基于上一步得到的各个边缘轮廓信息，对比面积、位置、周长等特征，筛选出最可能的轮廓，得到缺口位置。

​	

**2.准备工作**

​	在python环境中安装`opencv-python`库，可以通过pip进行安装

```
pip install opencv-python
```



**3.基本知识**

​	我们在滑动验证码的检测中需要两个基础方法（高斯滤波和边缘检测）

​	首先，彩色的图片相对比较复杂，它是一个三维矩阵，在opencv中提供一个方法，可以将图片灰度法，也即是将三维矩阵二维化，那么这样的计算量就会小很多。

```python
# 导入opencv-python
import cv2

# 用cv2读取图片
img_raw = cv2.imread("sliding.jpg")
#
grey = cv2.cvtColor(img_raw,cv2.COLOR_BGR2GRAY) # 彩图转为灰度图--》将三维矩阵二维化
# 窗口显示图片
cv2.imshow("original_img",grey)
# 图片持续时间 0表示无限时间
cv2.waitKey(0)
```

 

 ![image-20220512190915860](C:\Users\ACG1314\AppData\Roaming\Typora\typora-user-images\image-20220512190915860.png)

​	**高斯滤波**

​	高斯滤波用来去除图片的一些噪声，减少噪声干扰，其实就是把一张图片模糊化，为下一步的边缘检测做好铺垫。

​	在opencv中，有一个实现好的api可以直接调用高斯滤波:

```python
dst = cv.GaussianBlur(src,
					 ksize
					 sigmaX
					 [,dst
					 [,sigmaY
					 [,borderType]]])
#src：输入图像
#ksize：高斯滤波器的大小
#sigmaX：x方向上的高斯滤波器标准差
#dst：输出图像
#sigmaY：y方向上的高斯滤波器标准偏差
#borderType：像素边界外推法标志
```

​	**其中ksize和sigmaX是必传参数**，我们可以设置ksize = (5,5)   sigMax = 0

```python
# 高斯核大小
gauss_kernel_size = (5,5)
# X方向标准差
gauss_sigma_X = 0
# 高斯滤波
img_gauss = cv2.GaussianBlur(src=img_raw,ksize=gauss_kernel_size,sigmaX=gauss_sigma_X)
# 窗口显示高斯滤波后的图片
cv2.imshow("gauss_img",img_gauss)
# 图片持续时间 0表示无限时间
cv2.waitKey(0)
```

​															

 						  	高斯滤波后

![image-20220512191030655](C:\Users\ACG1314\AppData\Roaming\Typora\typora-user-images\image-20220512191030655.png) 



​	可以观察出，高斯滤波后的图片要比原图片模糊许多，这是因为高斯卷积核的平滑效果。





​	**边缘处理**

​	由于验证码图片里的目标缺口通常具有比较明显的边缘，所以借助一些边缘检测算法，再加上调整阈值是可以找出缺口位置的。目前应用比较广泛的边缘检测算法是Canny。原理推导：https://blog.csdn.net/m0_43609475/article/details/112775377

​	在opencv中，也有能实现Canny边缘检测算法的api：

```python
dst = cv2.Canny(image, 
			threshold1, 
			threshold2, 
			edges=None, 
			apertureSize=None, 
			L2gradient=None)
			
# image:需要处理的图片
# threshold1，threshold2：两个阈值，分别是最小判定临界点和最大判定临界点
# apertureSize：用于查找图片渐变的索贝尔内核的大小
# L2gradient：用于查找梯度幅度的等式
```

​	通常来说，只需要设置threshold1和threshold2的值即可，其数值大小需要视图片而定。这里我们可以设置为threshold1=150和threshold2=200。

```python
# 边缘检测
img_canny = cv2.Canny(image=img_gauss,threshold1=150,threshold2=200)
# 窗口显示高斯滤波后的图片
cv2.imshow("canny_img",img_canny)
# 图片持续时间 0表示无限时间
cv2.waitKey(0)
```

 ![image-20220512191150656](C:\Users\ACG1314\AppData\Roaming\Typora\typora-user-images\image-20220512191150656.png)



​	**轮廓提取**

​	进行边缘检测后，可以看到图片中会保留比较明显的边缘信息，下一步可以利用OpenCV技术提取出这些边缘的轮廓，这需要用到`findContours`方法，其方法如下

```python
cv2.findContours(image, mode, method, contours=None, hierarchy=None, offset=None)
# image：需要处理的图片
# mode：用于定义轮廓的检索模式，详情见OpenCV官方文档中对RetrievalModes的介绍。
# method：用以定义轮廓的近似方法，详情见OpenCV官方文档中对ContourApproxiamationModes的介绍
```

​	这里，我们将mode设置为cv2.RETR_CCOMP，method设置为cv2.CHAIN_APPROX_SIMPLE，具体原因可参考http://www.woshicver.com/，这里不展开讲解。



```python
# 轮廓提取
contours, _ = cv2.findContours(img_canny, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)
```



​	**外接矩阵**

​	提取到边缘轮廓后，可以计算出轮廓的外接矩阵，以便我们根据面积和周长等参数判断提取到的轮廓是不是目标缺口的轮廓。计算外接矩阵使用的方法是`cv2.boundingRect`

```python
def boundingRect(array):
# array: 灰度图或者2D点集，这里我们传入轮廓信息
```

​	我们可以根据提取到的轮廓去划外接矩阵的形状

```python
# 外接矩阵
for contour in contours:
    # 获取外接矩阵四个点的坐标
    x, y, w, h = cv2.boundingRect(contour)
    # 输出四个点坐标
    print(cv2.boundingRect(contour))
    # cv2.rectangle(img,坐标1,坐标2,划线颜色,线条粗度)
    # 根据两个顶点坐标画矩形
    cv2.rectangle(img_raw, (x, y), (x + w, y + h), (0, 0, 255), 2)

cv2.imwrite("image_label.png",img_raw)
```

![image-20220512193326219](C:\Users\ACG1314\AppData\Roaming\Typora\typora-user-images\image-20220512193326219.png)

​	从上图可以看出，我们已经成功获取了各个轮廓的外接矩形，很明显有些不是我们想要的，我们根据`面积`和`周长`等筛选缺口所在的位置。

​	于是需要用到计算轮廓`面积`的方法`cv2.contourArea`

```python
# 计算轮廓面积
def contourArea(contour, oriented=None): 
# contour:轮廓信息
```

​	以及需要用到计算轮廓`周长`的方法 `cv2.arcLength`

```python
# 计算轮廓周长
def arcLength(curve, closed):
# contour:轮廓信息
# closed:轮廓是否封闭
```

![image-20220512193326219](C:\Users\ACG1314\AppData\Roaming\Typora\typora-user-images\image-20220512193326219.png)



​	接下来我们就要想办法确定一个筛选条件就可以了，例如我们给`面积`设定一个范围，给`周长`设定一个范围，另外给缺口位置也设定一个范围。

​	首先，我们先获取一下验证码的长度和宽度

```python
# 验证码的长度和宽度
img_height, img_width = grey.shape
```



通过测量（这里建议用**PhotoShop**做一个简单测量），我们发现：

1. 目标缺口的外接矩形的高度大约是验证码高度的0.25倍，宽度大约是验证码宽度的0.15倍（允许误差在20％）
2. 缺口位置（左侧）有一个最小偏移量和一个最大偏移量，最小偏移量大概是验证码宽度的0.2倍，最大偏移量是验证码宽度的0.8倍

综合上述两个条件，我们可以得到三个阈值条件：

**① 面积的阈值条件**

```python
# 面积阈值条件
contour_area_min = (img_width * 0.15) * (img_height * 0.25) * 0.8
contour_area_max = (img_width * 0.15) * (img_height * 0.25) * 1.2
# 满足：(contour_are_min < cv2.contourArea(contour) < contour_are_max)
```

**② 周长的阈值条件**

```python
# 周长阈值条件
arc_length_min = ((img_width * 0.15) + (img_height * 0.25)) * 2 * 0.8
arc_length_max = ((img_width * 0.15) + (img_height * 0.25)) * 2 * 1.2
# 满足 (arc_length_min < cv2.arcLength(contour,True) < arc_length_max)
```

**③ 偏移量的阈值条件**

```python
# 偏移量的阈值条件：
offset_min = 0.2 * img_width
offset_max = 0.85 * img_width
# 满足  (offset_min < x < offset_max ) ，x为轮廓的左侧坐标
```



​	根据上述三个阈值条件设置IF判断，将最终满足的轮廓信息作为滑块缺口的外接矩阵，将外接矩阵划线到原图上，并且计算滑块缺口的偏移量。

```python
# 遍历所有的轮廓信息
for contour in contours:
    # 每个轮廓外接矩阵的四个点坐标
    x, y, w, h = cv2.boundingRect(contour)
    # 判断条件
    if (contour_area_min < cv2.contourArea(contour) < contour_area_max) and \
            (arc_length_min < cv2.arcLength(contour,True) < arc_length_max) and \
            (offset_min < x < offset_max ):
        # 当满足条件后
        # 将外接矩阵画到原图上
        cv2.rectangle(img_raw,(x,y),(x+w,y+h),(0,0,255),2)
        # 将该外接矩阵左侧点的坐标作为偏移量
        offset = x

# 保存到本地上
cv2.imwrite("image_label.png",img_raw)

# 打印偏移
print("offset：",offset)
```

​	经过计算得到，滑块缺口的偏移量为292px

 ![image-20220512195828069](C:\Users\ACG1314\AppData\Roaming\Typora\typora-user-images\image-20220512195828069.png)

 ![image-20220512195914345](C:\Users\ACG1314\AppData\Roaming\Typora\typora-user-images\image-20220512195914345.png)

​	

​	至此，我们就完成了《识别目标缺口的位置》，接下来我们将在第十二章中学习模拟浏览器的方式，进行滑动验证码的拖拽。



#### 实训五：滑块验证码目标缺口的识别

​	分析过程看上面

**完整代码**

```python
# 导入opencv-python
import cv2

# 用cv2读取图片
img_raw = cv2.imread("sliding.jpg")
# 灰度化图片
grey = cv2.cvtColor(img_raw,cv2.COLOR_BGR2GRAY) # 彩图转为灰度图--》将三维矩阵二维化

# 高斯核大小
gauss_kernel_size = (5,5)
# X方向标准差
gauss_sigma_X = 0
# 高斯滤波
img_gauss = cv2.GaussianBlur(src=grey,ksize=gauss_kernel_size,sigmaX=gauss_sigma_X)

# 边缘检测
img_canny = cv2.Canny(image=img_gauss,threshold1=150,threshold2=200)

# 轮廓提取
contours, _ = cv2.findContours(img_canny, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)

# 图片大小
img_height, img_width = grey.shape

# 面积阈值条件
contour_area_min = (img_width * 0.15) * (img_height * 0.25) * 0.8
contour_area_max = (img_width * 0.15) * (img_height * 0.25) * 1.2
# 满足：(contour_are_min < cv2.contourArea(contour) < contour_are_max)

# 周长阈值条件
arc_length_min = ((img_width * 0.15) + (img_height * 0.25)) * 2 * 0.8
arc_length_max = ((img_width * 0.15) + (img_height * 0.25)) * 2 * 1.2
# 满足 (arc_length_min < cv2.arcLength(contour,True) < arc_length_max)

# 偏移量的阈值条件：
offset_min = 0.2 * img_width
offset_max = 0.85 * img_width
# 满足  (offset_min < x < offset_max ) ，x为轮廓的左侧坐标

# 设置最初偏移量为None
offset = None

# 遍历所有的轮廓信息
for contour in contours:
    # 每个轮廓外接矩阵的四个点坐标
    x, y, w, h = cv2.boundingRect(contour)
    # 判断条件
    if (contour_area_min < cv2.contourArea(contour) < contour_area_max) and \
            (arc_length_min < cv2.arcLength(contour,True) < arc_length_max) and \
            (offset_min < x < offset_max ):
        # 当满足条件后
        # 将外接矩阵画到原图上
        cv2.rectangle(img_raw,(x,y),(x+w,y+h),(0,0,255),2)
        # 将该外接矩阵左侧点的坐标作为偏移量
        offset = x

# 保存到本地上
cv2.imwrite("image_label.png",img_raw)

# 打印偏移
print("offset：",offset)
```



### 10.3.4 深度学习识别验证码（了解，更新中）

​	通过10.3.3和10.3.4节，我们学习了使用OCR技术和图像处理技术识别验证码的方法，但这些方法有个共同的缺点，就是正确率不够高。从本节开始，我们来学习使用深度学习识别验证码的方法。

**1.准备工作**

​	在Python中，常用的深度学习框架有两个，一个是Pytorch，一个是Tensorflow。在本节中，我们主要使用Pytorch深度学习框架。

```
pip install torch torchvision
```



### 10.3.5 手机验证码的自动化处理（更新中）





